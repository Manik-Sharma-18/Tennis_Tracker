{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fb48e-8b17-4b9d-b771-8d367588cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c4a7d-3281-41c6-b15d-f32585e4ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Court dimensions for US Open Women's Singles ---\n",
    "COURT_WIDTH_METERS = 8.23\n",
    "COURT_LENGTH_METERS = 23.77\n",
    "\n",
    "# Load YOLOv8 pretrained Object Detection Model\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.conf = 0.4\n",
    "model.classes = [0]  # Only detect person class\n",
    "\n",
    "# Initialize DeepSORT\n",
    "tracker = DeepSort(max_age=15)\n",
    "\n",
    "# Court corner pixel coordinates (replace with accurate values)\n",
    "pixel_court_pts = np.array([\n",
    "    [374, 171],   # top-left\n",
    "    [838, 167],   # top-right\n",
    "    [1078, 607],  # bottom-right\n",
    "    [131, 619]    # bottom-left\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Real-world court points in meters\n",
    "real_court_pts = np.array([\n",
    "    [0, 0],\n",
    "    [COURT_WIDTH_METERS, 0],\n",
    "    [COURT_WIDTH_METERS, COURT_LENGTH_METERS],\n",
    "    [0, COURT_LENGTH_METERS]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Compute homography matrix\n",
    "homography_matrix, _ = cv2.findHomography(pixel_court_pts, real_court_pts)\n",
    "\n",
    "# Global dictionaries\n",
    "player_tracks = {}\n",
    "player_appearance_features = {}\n",
    "player_live_distances = {}\n",
    "track_id_to_player_name = {}\n",
    "cluster_to_player_name = {}\n",
    "\n",
    "# Track first few player IDs to anchor appearance clustering\n",
    "early_player_ids = set()\n",
    "MAX_EARLY_IDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886291f3-4d18-4189-a83d-337ec284273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_meters(coords):\n",
    "    pts = np.array(coords, dtype=np.float32).reshape(-1, 1, 2)\n",
    "    transformed = cv2.perspectiveTransform(pts, homography_matrix)\n",
    "    return transformed.reshape(-1, 2)\n",
    "\n",
    "\n",
    "def process_frame_with_tracking(frame):\n",
    "    results = model(frame, verbose=False)\n",
    "    person_detections = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = box.conf[0].cpu().item()\n",
    "        cls = int(box.cls[0].cpu().item())\n",
    "        if cls == 0 and conf >= model.conf:\n",
    "            person_detections.append([[x1, y1, x2 - x1, y2 - y1], conf, 'person'])\n",
    "\n",
    "    tracks = tracker.update_tracks(person_detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "\n",
    "        # Track early players (anchor the first two confirmed tracks)\n",
    "        if len(early_player_ids) < MAX_EARLY_IDS and track_id not in early_player_ids:\n",
    "            early_player_ids.add(track_id)\n",
    "\n",
    "        if track.features is not None:\n",
    "            if track_id not in player_appearance_features:\n",
    "                player_appearance_features[track_id] = []\n",
    "            feature = track.features[0]\n",
    "            if isinstance(feature, torch.Tensor):\n",
    "                feature = feature.cpu().numpy()\n",
    "            player_appearance_features[track_id].append(feature)\n",
    "\n",
    "            # Hard-code early known IDs as players\n",
    "            if len(player_appearance_features) >= 2 and 1 in player_appearance_features and 3 in player_appearance_features:\n",
    "                if track_id == 1:\n",
    "                    track_id_to_player_name[1] = \"Player A\"\n",
    "                elif track_id == 3:\n",
    "                    track_id_to_player_name[3] = \"Player B\"\n",
    "\n",
    "        l, t, r, b = track.to_ltrb()\n",
    "        cx, cy = int((l + r) / 2), int(b)\n",
    "        world_coord = to_meters([(cx, cy)])[0]\n",
    "\n",
    "        if track_id not in player_tracks:\n",
    "            player_tracks[track_id] = []\n",
    "            player_live_distances[track_id] = 0.0\n",
    "\n",
    "        if player_tracks[track_id]:\n",
    "            last_pos = player_tracks[track_id][-1]\n",
    "            dist = np.linalg.norm(world_coord - last_pos)\n",
    "            if dist < 10:  # Cap to avoid huge jumps (Safety Check)\n",
    "                player_live_distances[track_id] += dist\n",
    "            \n",
    "\n",
    "        player_tracks[track_id].append(world_coord)\n",
    "\n",
    "\n",
    "        # Use mapped name if available\n",
    "        display_name = track_id_to_player_name.get(track_id, f\"ID {track_id}\")\n",
    "\n",
    "        cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
    "        cv2.putText(frame, display_name, (int(l), int(t) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{player_live_distances[track_id]:.1f} m\", (int(l), int(t) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def merge_tracks_by_appearance():\n",
    "    avg_features = {tid: np.mean(np.vstack(feats), axis=0) for tid, feats in player_appearance_features.items() if feats}\n",
    "    track_ids = list(avg_features.keys())\n",
    "    if len(track_ids) <= 2:\n",
    "        return {i: [i] for i in track_ids}\n",
    "\n",
    "    feature_matrix = normalize(np.vstack([avg_features[tid] for tid in track_ids]))\n",
    "    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.5, metric='cosine', linkage='average')\n",
    "    labels = clustering.fit_predict(feature_matrix)\n",
    "\n",
    "    clusters = {}\n",
    "    for tid, label in zip(track_ids, labels):\n",
    "        clusters.setdefault(label, []).append(tid)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def assign_cluster_names(clusters):\n",
    "    # First, assign default names based on distance (sorted order)\n",
    "    sorted_clusters = sorted(clusters.items(), key=lambda item: -sum(player_live_distances.get(tid, 0.0) for tid in item[1]))\n",
    "    used_names = set()\n",
    "\n",
    "    for i, (cluster_label, tids) in enumerate(sorted_clusters):\n",
    "        name = f\"Player {'ABCD'[i] if i < 4 else i}\"\n",
    "\n",
    "        # Check for known IDs in the cluster and override the name\n",
    "        if 1 in tids:\n",
    "            name = \"Player A\"\n",
    "        elif 3 in tids:\n",
    "            name = \"Player B\"\n",
    "\n",
    "        # Avoid assigning the same name to two clusters\n",
    "        if name in used_names:\n",
    "            name = f\"Player {'ABCD'[i] if i < 4 else i}\"\n",
    "        used_names.add(name)\n",
    "\n",
    "        cluster_to_player_name[cluster_label] = name\n",
    "        for tid in tids:\n",
    "            track_id_to_player_name[tid] = name\n",
    "\n",
    "def is_wide_angle_frame(frame, min_players=2, spread_threshold=200, max_bbox_height=300):\n",
    "    results = model(frame, verbose=False)\n",
    "    player_centers_y = []\n",
    "    heights = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = box.conf[0].cpu().item()\n",
    "        cls = int(box.cls[0].cpu().item())\n",
    "        if cls == 0 and conf >= model.conf:\n",
    "            cy = (y1 + y2) / 2\n",
    "            h = y2 - y1\n",
    "            player_centers_y.append(cy)\n",
    "            heights.append(h)\n",
    "\n",
    "    if len(player_centers_y) < min_players:\n",
    "        return False\n",
    "\n",
    "    # If any bounding box is taller than max_bbox_height, consider zoomed-in\n",
    "    if any(h > max_bbox_height for h in heights):\n",
    "        return False\n",
    "\n",
    "    vertical_spread = max(player_centers_y) - min(player_centers_y)\n",
    "    return vertical_spread > spread_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4055e4-5303-4d39-b3d0-dbb0f038ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cap = cv2.VideoCapture(\"tennis_video_assignment.mp4\")\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter(\"output_processed_video.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "    frame_count = 0\n",
    "\n",
    "    #Visual Debug court points\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, test_frame = cap.read()\n",
    "    for pt in pixel_court_pts:\n",
    "        cv2.circle(test_frame, tuple(pt.astype(int)), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow(\"Court Calibration Check\", test_frame)\n",
    "    cv2.waitKey(0)\n",
    "    #\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        wide = is_wide_angle_frame(frame)\n",
    "        processed = process_frame_with_tracking(frame.copy()) if wide else frame.copy()\n",
    "        label = \"WIDE ANGLE\" if wide else \"ZOOMED\"\n",
    "        cv2.putText(processed, label, (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0) if wide else (0, 0, 255), 3)\n",
    "\n",
    "        out.write(processed)\n",
    "        cv2.imshow(\"Tennis Tracking\", processed)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"\\nFinal distances after merging appearances:\")\n",
    "    clusters = merge_tracks_by_appearance()\n",
    "    assign_cluster_names(clusters)\n",
    "\n",
    "    for cluster_label, tids in clusters.items():\n",
    "        merged_path = []\n",
    "        for tid in tids:\n",
    "            merged_path.extend(player_tracks.get(tid, []))\n",
    "\n",
    "        if len(merged_path) < 2:\n",
    "            continue\n",
    "\n",
    "        distances = [np.linalg.norm(np.array(merged_path[i]) - np.array(merged_path[i - 1])) for i in range(1, len(merged_path))]\n",
    "        total_distance = np.sum(distances)\n",
    "        name = cluster_to_player_name.get(cluster_label, f\"Cluster {cluster_label}\")\n",
    "        print(f\"{name}: {total_distance:.2f} meters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
